{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quasi Monte-Carlo integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "library(ggplot2, quietly=TRUE);\n",
    "library(randtoolbox, quietly=TRUE);\n",
    "\n",
    "# Decrease plot sizes\n",
    "options(repr.plot.width=4, repr.plot.height=4);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "\n",
    " * References\n",
    " * Monte Carlo integration (MC)\n",
    " * Sampling (QMC)\n",
    " * Low-discrepancy sequences\n",
    " * Sobol-sequences\n",
    " * High-dimensional Sobol-sequences and Brownian bridges\n",
    " \n",
    "\n",
    "## References\n",
    "\n",
    " * Numerical Recipes. The Art of Scientific Computing, 3rd Edition, 2007\n",
    "   Section 7.7, page 397-410\n",
    " * Christophe Dutang and Diethelm Wuertz - \"A note on random number generation\"\n",
    " https://cran.r-project.org/web/packages/randtoolbox/vignettes/fullpres.pdf https://github.com/cran/randtoolbox/blob/master/R/qmc.R\n",
    " * Xiaoqun Wang and Ian H. Sloan - Low Discrepancy Sequences in High Dimensions: How Well Are Their Projections Distributed?\n",
    "   https://www.maths.unsw.edu.au/sites/default/files/amr06_8_0.pdf\n",
    " * Junyi Lin, Xiaoqun Wang - New Brownian bridge construction in quasi-Monte Carlo methods for computational finance http://dx.doi.org/10.1016/j.jco.2007.06.001\n",
    " * Jacques Du Toit - A High-performance Brownian Bridge for GPUs: Lessons for bandwidth bound applications http://www.nag.co.uk/doc/techrep/pdf/tr2_12.pdf\n",
    " \n",
    " ![HIPERFIT logo](http://hiperfit.dk/images/logo114x114.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo integration\n",
    "\n",
    "Monte Carlo integration provides a general method of computing multivariate integrals through random sampling. Many problems can be transformed into the computation of the integral of some function $f$ on the d-dimensional unit hypercube $[0,1]^d$:\n",
    "\n",
    "\\begin{equation}\n",
    "\\int_{[0,1]^d} \\! f(\\mathbf{x}) \\, \\mathrm{d}\\mathbf{x}. \\quad \\mathbf{x} = (x_1, \\ldots, x_d)\n",
    "\\end{equation}\n",
    "\n",
    "We can estimate this integral by picking $N$ uniformly distributed points in $[0,1]^d$ by averaging:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{1}{n}\\sum\\limits_{i=1}^n\\; f(\\mathbf{x}_n), \n",
    "\\end{equation}\n",
    "\n",
    "And as we increase N, we increase the precision of our approximation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\lim_{n\\to\\infty}\\; \\frac{1}{n}\\sum\\limits_{i=1}^n\\; f(\\mathbf{x}_n) = \\int_{[0,1]^s} \\! f(\\mathbf{x}) \\, \\mathrm{d}\\mathbf{x}.\n",
    "\\end{equation}\n",
    "\n",
    "If we select the points uniformly from the hypercube, the approximation will converge faster. Thus to improve efficiency, the main problem is how to select the sampling points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "We can use either of these approaches to generate points in the unit hypercube:\n",
    "\n",
    " * Uniform grid\n",
    " * Pseudo-random number generation (PRNG)\n",
    " * Quasi-random number generation (QRNG)\n",
    " * or a combination (e.g. using many PRNGs for different subintervals, this is called stratified sampling)\n",
    "\n",
    "### Uniform grid\n",
    "The most basic approach will be to generate a uniform grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w <- 20\n",
    "ggplot(data = data.frame(x=((0:(w*w-1))%/%w)/w,y=((0:(w*w-1))%%w)/w), aes(x,y))+ geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is that we with this approach have to select the resolution of the grid in advance. We usually don't know how long to iterate in advance, and often we want to the algorithm to continue until we reach some precision.\n",
    "\n",
    "### Pseudo-random number generation\n",
    "With pseudo-random number generation we will be able to do this, but the points can clumb together or leave larger unfilled regions. Evaluating $f(\\mathbf{x})$ at a point close to another one we have already used, will not give much new information and will thus not improve on our current approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n <- 400\n",
    "set.generator(\"MersenneTwister\", initialization=\"init2002\", resolution=53, seed=12345)\n",
    "mersenne_frame <- data.frame(x=runif(n), y=runif(n))\n",
    "ggplot(data = mersenne_frame, aes(x,y))+ geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quasi-random sequences\n",
    "In contrast, Quasi-random number generators does not aim to be truly random, they instead generate points in a more structured fashion, filling more and more of unit hypercube. After calculating 400 2D-points of the Torus algorithm (Kronecker sequences), we obtain the following pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n <- 400\n",
    "torus_sequence <- torus(n, dim = 2)\n",
    "ggplot(data = data.frame(x=torus_sequence[,1],y=torus_sequence[,2]), aes(x,y))+ geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But unlike uniform grid, we can continue to fill in more and more points in-between those already generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n <- 2000\n",
    "torus_sequence <- torus(n, dim = 2)\n",
    "ggplot(data = data.frame(x=torus_sequence[,1],y=torus_sequence[,2]), aes(x,y))+ geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-discrepancy sequences\n",
    "Sequences, such as the one generated by the Torus algorithm above, are called *low-discrepancy sequences* and the algorithms for generating them are called *quasi-random number generators* (QRNGs). The basic idea for these algorithms is to generate proportionally equal amounts of samples in each subinterval, thus limiting the number of empty regions and regions with high sample density.\n",
    "\n",
    "On Wikipedia we find the following definition of discrepancy:\n",
    "<blockquote>\n",
    "The *discrepancy* of a set $P = \\{ x_1, \\ldots, x_N\\}$ is defined, using Niederreiter's notation, as\n",
    "\n",
    "\\begin{equation}\n",
    "D_N(P) = \\sup_{B\\in J}\n",
    "  \\left|  \\frac{A(B;P)}{N} - \\lambda_s(B)  \\right|\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    "$Î»_s$ is the $s$-dimensional Lebesgue measure,\n",
    "$A(B;P)$ is the number of points in $P$ that fall into $B$,\n",
    "and $J$ is the set of $s$-dimensional intervals or boxes of the form\n",
    "\n",
    "\\begin{equation}\n",
    "\\prod_{i=1}^s [a_i, b_i) = \\{ \\mathbf{x} \\in \\mathbf{R}^s : a_i \\le x_i < b_i \\} \\,\n",
    "\\end{equation}\n",
    "\n",
    "where $0 \\le a_i < b_i \\le 1$.\n",
    "</blockquote>\n",
    "\n",
    "This can be understood as finding the region in the point set, with the largest difference between observed size $\\left(\\frac{A(B;P)}{N}\\right)$ and actual size $\\left(\\lambda_s(B)\\right)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sobol sequences\n",
    " \n",
    "This section should cover:\n",
    " * Direction numbers\n",
    " * How to generate them efficiently\n",
    " * Scrambling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-dimensional Sobol-sequences and Brownian bridge\n",
    "Sobol sequences with many dimensions expose a different problem, that needs to be tackled. For the first couple of dimensions, Sobol numbers have good space coverage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n <- 16000\n",
    "dimensions = 30\n",
    "sobol_sequence <- sobol(n, dim = dimensions)\n",
    "sobol_frame <- data.frame(x=sobol_sequence[,1],y=sobol_sequence[,2])\n",
    "ggplot(data = sobol_frame[0:4000,], aes(x,y))+ geom_point() + xlab(\"dimension 1\") + ylab(\"dimension 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But on the higher dimensions of the Sobol-sequence, the quality decreases significantly. We can illustrate by showing the 29th and 30th dimension of the same sequence as was plotted above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sobol_frame <- data.frame(x=sobol_sequence[,29],y=sobol_sequence[,30])\n",
    "ggplot(data = sobol_frame[0:4000,], aes(x,y)) + geom_point() + xlab(\"dimension 29\") + ylab(\"dimension 30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in the sequence, the gaps disappear. Here we plot the last dimensions with 8000 and 16000 points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ggplot(data = sobol_frame[0:8000,], aes(x,y)) + geom_point() + xlab(\"dimension 29\") + ylab(\"dimension 30\")\n",
    "ggplot(data = sobol_frame[0:16000,], aes(x,y)) + geom_point() + xlab(\"dimension 29\") + ylab(\"dimension 30\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Brownian bridge for path generation w. Sobol-numbers\n",
    "When Sobol-sequences are used for path-generation, a strategy has been devised to tackle the above problem of little variation in the higher dimensions.\n",
    "\n",
    "Instead of using each dimension in sequence to generate a path, the lower-dimension (higher quality) dimensions are used to generate the big steps of the sequence, while the latter dimensions are only used to \"fill in the holes\" (only taking small steps).\n",
    "\n",
    "This can be done by using the Brownian bridge formula:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
